{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": [],
   "gpuType": "T4",
   "authorship_tag": "ABX9TyPgp+mgS35tuy/gwXtJBSNh"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aWJiAT59Ej2t"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import copy\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "\n",
    "random_seed = 2022\n",
    "\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ],
   "metadata": {
    "id": "rTcCk9GQEsjd"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def list_image_files(data_dir, sub_dir):\n",
    "    image_format = [\"jpeg\", \"jpg\", \"png\"]\n",
    "\n",
    "    image_files = []\n",
    "    images_dir = os.path.join(data_dir, sub_dir)\n",
    "    for file_path in os.listdir(images_dir):\n",
    "        if file_path.split(\".\")[-1] in image_format:\n",
    "            image_files.append(os.path.join(sub_dir, file_path))\n",
    "    return image_files"
   ],
   "metadata": {
    "id": "TRDfVoOkE1bZ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "data_dir = \"/content/drive/MyDrive/lettuce/train/\"\n",
    "\n",
    "Bacterial_list = list_image_files(data_dir, \"Bacterial\")\n",
    "fungal_list = list_image_files(data_dir, \"fungal\")\n",
    "healthy_list = list_image_files(data_dir, \"healthy\")"
   ],
   "metadata": {
    "id": "uTpj43MpE2jE"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_RGB_image(data_dir, file_name):\n",
    "    image_file = os.path.join(data_dir, file_name)\n",
    "    image = cv2.imread(image_file)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return image"
   ],
   "metadata": {
    "id": "6P_3-7fOE4vb"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "min_num_files = min(len(Bacterial_list), len(fungal_list), len(healthy_list))\n",
    "\n",
    "@interact(index=(0, min_num_files-1))\n",
    "def show_samples(index=0):\n",
    "    Bacterial_image = get_RGB_image(data_dir, Bacterial_list[index])\n",
    "    fungal_image = get_RGB_image(data_dir, fungal_list[index])\n",
    "    healthy_image = get_RGB_image(data_dir, healthy_list[index])\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.subplot(131)\n",
    "    plt.title(\"Bacterial\")\n",
    "    plt.imshow(Bacterial_image)\n",
    "    plt.subplot(132)\n",
    "    plt.title(\"fungal\")\n",
    "    plt.imshow(fungal_image)\n",
    "    plt.subplot(133)\n",
    "    plt.title(\"healthy\")\n",
    "    plt.imshow(healthy_image)\n",
    "    plt.tight_layout()"
   ],
   "metadata": {
    "id": "klts2IvoE7Mr"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_data_dir = \"/content/drive/MyDrive/lettuce/train/\"\n",
    "class_list = [\"Bacterial\", \"fungal\", \"healthy\"]\n",
    "\n",
    "class Chest_dataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        Bacterial = list_image_files(data_dir, \"Bacterial\")\n",
    "        fungal = list_image_files(data_dir, \"fungal\")\n",
    "        healthy = list_image_files(data_dir, \"healthy\")\n",
    "\n",
    "\n",
    "        self.files_path = Bacterial + fungal + healthy\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files_path)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_file = os.path.join(self.data_dir, self.files_path[index])\n",
    "        image = cv2.imread(image_file)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # target = class_list.index(self.files_path[index].split(os.sep)[-2])\n",
    "\n",
    "        target = class_list.index(self.files_path[index].split(os.sep)[0])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            target = torch.Tensor([target]).long()\n",
    "\n",
    "        return {\"image\":image, \"target\":target}\n",
    "\n",
    "dset = Chest_dataset(train_data_dir)"
   ],
   "metadata": {
    "id": "UZCFP6TAE9u8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "index = 150\n",
    "plt.title(class_list[dset[index][\"target\"]])\n",
    "plt.imshow(dset[index][\"image\"])"
   ],
   "metadata": {
    "id": "xOa4CJ1qFFcr"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "transformer = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                         std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "train_dset = Chest_dataset(train_data_dir, transformer)\n",
    "index = 200\n",
    "image = train_dset[index][\"image\"]\n",
    "label = train_dset[index][\"target\"]\n",
    "\n",
    "print(image.shape, label)"
   ],
   "metadata": {
    "id": "wCamUBIZFGXB"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def build_dataloader(train_data_dir, val_data_dir):\n",
    "    dataloaders = {}\n",
    "    train_dset = Chest_dataset(train_data_dir, transformer)\n",
    "    dataloaders[\"train\"] = DataLoader(train_dset, batch_size=4, shuffle=True, drop_last=True)\n",
    "    val_dset = Chest_dataset(val_data_dir, transformer)\n",
    "    dataloaders[\"val\"] = DataLoader(val_dset, batch_size=1, shuffle=False, drop_last=False)\n",
    "    return dataloaders"
   ],
   "metadata": {
    "id": "_nZgqIy0FJL_"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_data_dir = \"/content/drive/MyDrive/lettuce/train/\"\n",
    "val_data_dir = \"/content/drive/MyDrive/lettuce/test/\"\n",
    "dataloaders = build_dataloader(train_data_dir, val_data_dir)"
   ],
   "metadata": {
    "id": "AvSy65V7FLoA"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = models.vgg19(pretrained=True)\n",
    "\n",
    "from torchsummary import summary\n",
    "summary(model, (3, 224, 224), batch_size=1, device=\"cpu\")\n"
   ],
   "metadata": {
    "id": "Zt6peFELFNuZ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.avgpool = nn.AdaptiveAvgPool2d(output_size=(1,1))\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(512, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.1),\n",
    "    nn.Linear(256, 3),  #len(class_list)\n",
    "    nn.Sigmoid()\n",
    ")"
   ],
   "metadata": {
    "id": "ku4ez9iOFP1i"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def build_vgg19_based_model(device_name='c'):\n",
    "    device = torch.device(device_name)\n",
    "    model = models.vgg19(pretrained=True)\n",
    "    model.avgpool = nn.AdaptiveAvgPool2d(output_size=(1,1))\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(512, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, 3), #len(class_list)\n",
    "        nn.Softmax(dim=1)\n",
    "    )\n",
    "    return model.to(device)"
   ],
   "metadata": {
    "id": "SNOxnedEFUFr"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = build_vgg19_based_model(device_name='cpu')\n",
    "\n",
    "from torchsummary import summary\n",
    "summary(model, (3, 224, 224), batch_size=1, device=\"cpu\")"
   ],
   "metadata": {
    "id": "_lljW_IxFWiL"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "loss_func = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr= 1E-3, momentum=0.9)\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_accuracy(image, target, model):\n",
    "    batch_size = image.shape[0]\n",
    "    prediction = model(image)\n",
    "    _, pred_label = torch.max(prediction, dim=1)\n",
    "    is_correct = (pred_label == target)\n",
    "    return is_correct.cpu().numpy().sum() / batch_size"
   ],
   "metadata": {
    "id": "6ZDSytB1FiYQ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cpu\")\n",
    "\n",
    "train_data_dir = \"/content/drive/MyDrive/lettuce/train/\"\n",
    "val_data_dir = \"/content/drive/MyDrive/lettuce/test/\"\n",
    "\n",
    "dataloaders = build_dataloader(train_data_dir, val_data_dir)\n",
    "model = build_vgg19_based_model()\n",
    "loss_func = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr= 1E-3, momentum=0.9)"
   ],
   "metadata": {
    "id": "Oa3H_pYtFke3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import copy\n",
    "\n",
    "# 모델을 저장하는 함수\n",
    "def save_best_model(model_state, model_name, save_dir=\"/content/drive/MyDrive/lettuce\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    torch.save(model_state, os.path.join(save_dir, model_name))\n",
    "\n",
    "# 모델 학습 함수\n",
    "def train_one_epoch(dataloaders, model, optimizer, loss_func, device):\n",
    "    losses = {}\n",
    "    accuracies = {}\n",
    "    for phase in [\"train\", \"val\"]:\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0\n",
    "\n",
    "        if phase == \"train\":\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "\n",
    "        for index, batch in enumerate(dataloaders[phase]):\n",
    "            image = batch[\"image\"].to(device)\n",
    "            target = batch[\"target\"].squeeze(1).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(phase == \"train\"):\n",
    "                prediction = model(image)\n",
    "                loss = loss_func(prediction, target)\n",
    "\n",
    "                if phase == \"train\":\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            running_correct += get_accuracy(image, target, model)\n",
    "\n",
    "            if phase == \"train\":\n",
    "                if index % 10 == 0:\n",
    "                    print(f\"{index}/{len(dataloaders[phase])} - Running Loss: {loss.item()}\")\n",
    "\n",
    "        losses[phase] = running_loss / len(dataloaders[phase])\n",
    "        accuracies[phase] = running_correct / len(dataloaders[phase])\n",
    "    return losses, accuracies\n",
    "\n",
    "# 기본 설정\n",
    "device = torch.device(\"cpu\")\n",
    "train_data_dir = \"/content/drive/MyDrive/lettuce/train/\"\n",
    "val_data_dir = \"/content/drive/MyDrive/lettuce/test/\"\n",
    "\n",
    "dataloaders = build_dataloader(train_data_dir, val_data_dir)\n",
    "model = build_vgg19_based_model()\n",
    "loss_func = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "optimizer = optim.SGD(model.parameters(), lr=1E-3, momentum=0.9)\n",
    "\n",
    "num_epochs = 2\n",
    "best_acc = 0.0\n",
    "\n",
    "# 학습 루프\n",
    "for epoch in range(num_epochs):\n",
    "    losses, accuracies = train_one_epoch(dataloaders, model, optimizer, loss_func, device)\n",
    "    print(f\"{epoch+1}/{num_epochs}-Train Loss: {losses['train']}, Val Loss: {losses['val']}\")\n",
    "    print(f\"{epoch+1}/{num_epochs}-Train Acc: {accuracies['train']}, Val Acc: {accuracies['val']}\")\n",
    "\n",
    "    # 최고의 검증 정확도를 가진 모델 저장\n",
    "    if accuracies[\"val\"] > best_acc:\n",
    "        best_acc = accuracies[\"val\"]\n",
    "        best_model = copy.deepcopy(model.state_dict())\n",
    "\n",
    "# 최고의 모델 저장\n",
    "save_best_model(best_model, \"best_model.pth\")\n",
    "print(\"Best model saved successfully.\")\n"
   ],
   "metadata": {
    "id": "co9BgRlGeCXb"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "print(\"Is directory exists:\", os.path.isdir(\"/content/drive/MyDrive/tomatos/save_best_model\"))\n"
   ],
   "metadata": {
    "id": "clznRPcPcmdY"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(6, 5))\n",
    "plt.subplot(211)\n",
    "plt.plot(train_loss, label=\"train\")\n",
    "plt.plot(val_loss,  label=\"val\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.grid(\"on\")\n",
    "plt.legend()\n",
    "plt.subplot(212)\n",
    "plt.plot(train_accuracy, label=\"train\")\n",
    "plt.plot(val_accuracy, label=\"val\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.grid(\"on\")\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ],
   "metadata": {
    "id": "B31RICbKFyJp"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "@torch.no_grad()\n",
    "def model_predict(image, model):\n",
    "    tensor_image = preprocess_image(image)\n",
    "    prediction = model(tensor_image)\n",
    "\n",
    "    _, pred_label = torch.max(prediction.detach(), dim=1)\n",
    "    pred_label = pred_label.squeeze(0)\n",
    "    return pred_label.item()"
   ],
   "metadata": {
    "id": "nvK-xhM_F9uR"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "ckpt = torch.load(\"/content/drive/MyDrive/lettuce/best_model2.pth\")\n",
    "\n",
    "model = build_vgg19_based_model()\n",
    "model.load_state_dict(ckpt)\n",
    "model.eval()"
   ],
   "metadata": {
    "id": "HTPzVbmTGA0J"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
