{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "id": "-dPkszDj1RMp"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jbE5ZXo8yIrV"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import random\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "\n",
    "random_seed = 2024\n",
    "\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def list_image_files(data_dir, sub_dir):\n",
    "    image_format = [\"jpg\"]\n",
    "\n",
    "    image_files = []\n",
    "    images_dir = os.path.join(data_dir, sub_dir)\n",
    "    for file_path in os.listdir(images_dir):\n",
    "        if file_path.split(\".\")[-1] in image_format:\n",
    "            image_files.append(os.path.join(sub_dir, file_path))\n",
    "    return image_files"
   ],
   "metadata": {
    "id": "iay1W9w-0TuU"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "data_dir = \"/content/drive/MyDrive/tomatos/train/\"\n",
    "\n",
    "Step1_list = list_image_files(data_dir, \"Step1\")\n",
    "Step2_list = list_image_files(data_dir, \"Step2\")\n",
    "Step3_list = list_image_files(data_dir, \"Step3\")\n",
    "Step4_list = list_image_files(data_dir, \"Step4\")\n",
    "Step5_list = list_image_files(data_dir, \"Step5\")"
   ],
   "metadata": {
    "id": "M7Bpebm70cgy"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_RGB_image(data_dir, file_name):\n",
    "    image_file = os.path.join(data_dir, file_name)\n",
    "    image = cv2.imread(image_file)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return image"
   ],
   "metadata": {
    "id": "uqr8XrC9NKGu"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "min_num_files = min(len(Step1_list), len(Step2_list), len(Step3_list), len(Step4_list), len(Step5_list))\n",
    "\n",
    "@interact(index=(0, min_num_files-1))\n",
    "def show_samples(index=0):\n",
    "    S1_image = get_RGB_image(data_dir, Step1_list[index])\n",
    "    S2_image = get_RGB_image(data_dir, Step2_list[index])\n",
    "    S3_image = get_RGB_image(data_dir, Step3_list[index])\n",
    "    S4_image = get_RGB_image(data_dir, Step4_list[index])\n",
    "    S5_image = get_RGB_image(data_dir, Step5_list[index])\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    plt.subplot(131)\n",
    "    plt.title(\"S1\")\n",
    "    plt.imshow(S1_image)\n",
    "    plt.subplot(132)\n",
    "    plt.title(\"S2\")\n",
    "    plt.imshow(S2_image)\n",
    "    plt.subplot(133)\n",
    "    plt.title(\"S3\")\n",
    "    plt.imshow(S3_image)\n",
    "    plt.subplot(134)\n",
    "    plt.title(\"S4\")\n",
    "    plt.imshow(S4_image)\n",
    "    plt.subplot(135)\n",
    "    plt.title(\"S5\")\n",
    "    plt.imshow(S5_image)\n",
    "    plt.tight_layout()"
   ],
   "metadata": {
    "id": "F3mtrub6NSH_"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(len(Step1_list))\n",
    "print(len(Step2_list))\n",
    "print(len(Step3_list))\n",
    "print(len(Step4_list))\n",
    "print(len(Step5_list))"
   ],
   "metadata": {
    "id": "tnAKTcoOOfuK"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_data_dir = \"/content/drive/MyDrive/tomatos/train/\"\n",
    "class_list = [\"Step1\", \"Step2\", \"Step3\", \"Step4\", \"Step5\"]"
   ],
   "metadata": {
    "id": "CVPF8v9hUpW5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "\n",
    "class ChestDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        Step1 = list_image_files(data_dir, \"Step1\")\n",
    "        Step2 = list_image_files(data_dir, \"Step2\")\n",
    "        Step3 = list_image_files(data_dir, \"Step3\")\n",
    "        Step4 = list_image_files(data_dir, \"Step4\")\n",
    "        Step5 = list_image_files(data_dir, \"Step5\")\n",
    "\n",
    "        self.files_path = Step1 + Step2 + Step3 + Step4 + Step5\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files_path)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_file = os.path.join(self.data_dir, self.files_path[index])\n",
    "        image = Image.open(image_file).convert(\"RGB\")  # PIL로 이미지 열기 및 BGR에서 RGB로 변환\n",
    "\n",
    "        target = class_list.index(self.files_path[index].split(os.sep)[0])  # 타겟을 클래스 인덱스로 설정\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, target\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "8I27S3-LV-h-"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dset = Chest_dataset(train_data_dir)"
   ],
   "metadata": {
    "id": "kJ8OvaEkWipc"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "index = 1\n",
    "plt.title(class_list[dset[index][\"target\"]])\n",
    "plt.imshow(dset[index][\"image\"])"
   ],
   "metadata": {
    "id": "r5Y1fVwJXDTy"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "transformer = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                         std=[0.5, 0.5, 0.5])\n",
    "])"
   ],
   "metadata": {
    "id": "7heeB4n8XK9q"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_dset = Chest_dataset(train_data_dir, transformer)"
   ],
   "metadata": {
    "id": "8-zvEXbEXPyf"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "index = 200\n",
    "image = train_dset[index][\"image\"]\n",
    "label = train_dset[index][\"target\"]"
   ],
   "metadata": {
    "id": "5Cc7A7oCXTA-"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(image.shape, label)"
   ],
   "metadata": {
    "id": "7eNK_ez-XW9V"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def build_dataloader(train_data_dir, val_data_dir):\n",
    "    dataloaders = {}\n",
    "    train_dset = Chest_dataset(train_data_dir, transformer)\n",
    "    dataloaders[\"train\"] = DataLoader(train_dset, batch_size=4, shuffle=True, drop_last=True)\n",
    "\n",
    "    val_dset = Chest_dataset(val_data_dir, transformer)\n",
    "    dataloaders[\"val\"] = DataLoader(val_dset, batch_size=1, shuffle=False, drop_last=False)\n",
    "    return dataloaders"
   ],
   "metadata": {
    "id": "Jp4ZHFBEXaO-"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_data_dir = \"/content/drive/MyDrive/tomatos/train/\"\n",
    "val_data_dir = \"/content/drive/MyDrive/tomatos/test/\"\n",
    "dataloaders = build_dataloader(train_data_dir, val_data_dir)"
   ],
   "metadata": {
    "id": "9SfMm7TkXk75"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = models.vgg19(pretrained=True)"
   ],
   "metadata": {
    "id": "CPY-apd4X-xi"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (3, 224, 224), batch_size=1, device=\"cpu\")"
   ],
   "metadata": {
    "id": "3nz02t72YD0_"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def build_vgg19_based_model(device_name='cpu'):\n",
    "    device = torch.device(device_name)\n",
    "    model = models.vgg19(pretrained=True)\n",
    "    model.avgpool = nn.AdaptiveAvgPool2d(output_size=(1,1))\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(512, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, len(class_list)),\n",
    "        nn.Softmax(dim=1)\n",
    "    )\n",
    "    return model.to(device)"
   ],
   "metadata": {
    "id": "ZNCQv46mYOwb"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = build_vgg19_based_model(device_name='cpu')"
   ],
   "metadata": {
    "id": "u6JqRMOGYRSL"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (3, 224, 224), batch_size=1, device=\"cpu\")"
   ],
   "metadata": {
    "id": "ma9LmLpBYUfI"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "loss_func = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr= 1E-3, momentum=0.9)"
   ],
   "metadata": {
    "id": "-BK_cVCdYX-j"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "@torch.no_grad()\n",
    "def get_accuracy(image, target, model):\n",
    "    batch_size = image.shape[0]\n",
    "    prediction = model(image)\n",
    "    _, pred_label = torch.max(prediction, dim=1)\n",
    "    is_correct = (pred_label == target)\n",
    "    return is_correct.cpu().numpy().sum() / batch_size"
   ],
   "metadata": {
    "id": "Dpl-crR8YiYL"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cpu\")"
   ],
   "metadata": {
    "id": "xkhr7-AtYnNi"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "ddevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_data_dir = \"/content/drive/MyDrive/tomatos/train/\"\n",
    "val_data_dir = \"/content/drive/MyDrive/tomatos/test/\"\n",
    "\n",
    "dataloaders = build_dataloader(train_data_dir, val_data_dir)\n",
    "model = build_vgg19_based_model()\n",
    "loss_func = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr= 1E-3, momentum=0.9)\n"
   ],
   "metadata": {
    "id": "Vn76WPoBYwbb"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "data_data = \"../DATASET/Classification/test/\"\n",
    "class_list = [\"Normal\", \"Covid\", \"Viral Pneumonia\"]\n",
    "\n",
    "test_normals_list = list_image_files(data_dir, \"Normal\")\n",
    "test_covids_list = list_image_files(data_dir, \"Covid\")\n",
    "test_pneumonias_list = list_image_files(data_dir, \"Viral Pneumonia\")"
   ],
   "metadata": {
    "id": "WcDjbRxwt8AX"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "\n",
    "# 클래스 리스트 업데이트\n",
    "class_list = ['Step1', 'Step2', 'Step3', 'Step4', 'Step5']\n",
    "\n",
    "# 데이터셋 클래스 정의\n",
    "class ChestDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        Step1 = list_image_files(data_dir, \"Step1\")\n",
    "        Step2 = list_image_files(data_dir, \"Step2\")\n",
    "        Step3 = list_image_files(data_dir, \"Step3\")\n",
    "        Step4 = list_image_files(data_dir, \"Step4\")\n",
    "        Step5 = list_image_files(data_dir, \"Step5\")\n",
    "\n",
    "        self.files_path = Step1 + Step2 + Step3 + Step4 + Step5\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files_path)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_file = os.path.join(self.data_dir, self.files_path[index])\n",
    "        image = Image.open(image_file).convert(\"RGB\")  # PIL로 이미지 열기 및 BGR에서 RGB로 변환\n",
    "\n",
    "        target = class_list.index(self.files_path[index].split(os.sep)[0])  # 타겟을 클래스 인덱스로 설정\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, target\n",
    "\n",
    "# 학습 함수 정의\n",
    "def train_one_epoch(model, data_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in data_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(data_loader.dataset)\n",
    "    epoch_accuracy = correct / total\n",
    "    return epoch_loss, epoch_accuracy\n",
    "\n",
    "# 데이터 경로 리스트를 가져오는 함수 정의\n",
    "def list_image_files(data_dir, sub_dir):\n",
    "    image_format = [\".jpg\", \".jpeg\", \".png\"]\n",
    "    image_files = []\n",
    "    images_dir = os.path.join(data_dir, sub_dir)\n",
    "    for file_path in os.listdir(images_dir):\n",
    "        if file_path.split(\".\")[-1] in image_format:\n",
    "            image_files.append(os.path.join(sub_dir, file_path))\n",
    "    return image_files\n",
    "\n",
    "# GPU 사용 가능 여부 확인 및 디바이스 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 데이터 전처리 및 데이터로더 생성\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "train_dataset = ChestDataset(train_data_dir, transform=transform)\n",
    "val_dataset = ChestDataset(val_data_dir, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset_dir, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset_dir, batch_size=16)\n",
    "\n",
    "# 모델 생성 및 출력 레이어 수정\n",
    "num_classes = 5\n",
    "model = models.vgg19(pretrained=True)\n",
    "model.classifier[-1] = nn.Linear(4096, num_classes)  # 출력 레이어 수정\n",
    "model = model.to(device)\n",
    "\n",
    "# 손실 함수 및 옵티마이저 설정\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# 학습 진행\n",
    "num_epochs = 10\n",
    "best_accuracy = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_accuracy = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss}, Train Accuracy: {train_accuracy}\")\n",
    "\n",
    "    # 검증 성능 측정 및 모델 저장\n",
    "    with torch.no_grad():\n",
    "        val_loss, val_accuracy = train_one_epoch(model, val_loader, optimizer, criterion, device)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Val Loss: {val_loss}, Val Accuracy: {val_accuracy}\")\n",
    "        if val_accuracy > best_accuracy:\n",
    "            best_accuracy = val_accuracy\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "\n",
    "print(f\"Best Validation Accuracy: {best_accuracy}\")\n"
   ],
   "metadata": {
    "id": "KrMbM7Qj5Mkh"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
